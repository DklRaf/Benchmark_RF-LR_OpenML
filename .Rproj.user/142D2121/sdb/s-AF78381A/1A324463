{
    "collab_server" : "",
    "contents" : "rm(list = ls())\nlibrary(mlr)\nlibrary(gridExtra)\nlibrary(ggplot2)\nlibrary(cowplot)\nlibrary(reshape2)\n\n\n## Load and convert the reasults to a data frame ----\nload(file  = \"../Data_BenchmarkOpenMl/Final/Results/Windows/benchmark_results_snow_strat.RData\")\n\n# aggregate the results\nres.perfs = lapply(result, function(x) getBMRAggrPerformances(x, as.df=TRUE))\n\n# detect and removes the nas\nres.perfs.nas = which(sapply(res.perfs, function(x) any(is.na(x))))\nres.perfs = res.perfs[-res.perfs.nas]\nclas_used = clas_used[-res.perfs.nas,]\n\n# convert to a data.frame\nres.perfs.df = do.call(\"rbind\", res.perfs) \n\n# get the difference of performances\nperfsAggr.LR = subset(res.perfs.df, learner.id==\"classif.logreg\")\nperfsAggr.RF = subset(res.perfs.df, learner.id==\"classif.randomForest\")\nperfsAggr.diff = perfsAggr.RF[,3:ncol(perfsAggr.RF)]-perfsAggr.LR[,3:ncol(perfsAggr.LR)]\nperfsAggr.diff.melted = melt(perfsAggr.diff)\ndetach(package:reshape2, unload = TRUE)\n\n## Compute the dataset of difference\ndf.bmr.diff = data.frame(perfsAggr.RF[,c(3:ncol(perfsAggr.RF))]-perfsAggr.LR[,c(3:ncol(perfsAggr.LR))],\n                         logp = log(clas_used$NumberOfFeatures), \n                         logn = log(clas_used$NumberOfInstances),\n                         logdimension = log(clas_used$dimension),\n                         logpsurn = log(clas_used$NumberOfFeatures/clas_used$NumberOfInstances),\n                         logdimensionsurn = log(clas_used$dimension/clas_used$NumberOfInstances),\n                         lograpportMajorityMinorityClass = log(clas_used$MajorityClassSize/clas_used$MinorityClassSize))\n\n\npaste(\"Is there any nas ? :\", any(is.na(df.bmr.diff)))\n\n\n## Compute the ranks\nconvertModifiedBMRToRankMatrix <- function(bmr.all, measure = NULL, ties.method = \"average\") {\n  \n  measure.name = paste(measure$id,\".test.mean\", sep = \"\")\n  df = aggregate(bmr.all[[measure.name]], by = list(task.id = bmr.all$task.id,\n                                                    learner.id = bmr.all$learner.id),\n                 FUN = mean)\n  \n  # calculate ranks, rank according to minimize option of the measure\n  if (!measure$minimize)\n    df$x = -df$x\n  df = plyr::ddply(df, \"task.id\", function(d) {\n    d$alg.rank = rank(d$x, ties.method = ties.method)\n    return(d)\n  })\n  \n  # convert into matrix, rows = leaner, cols = tasks\n  df = reshape2::melt(df, c(\"task.id\", \"learner.id\"), \"alg.rank\")\n  df = reshape2::dcast(df, learner.id ~ task.id )\n  task.id.names = setdiff(colnames(df), \"learner.id\")\n  mat = as.matrix(df[, task.id.names])\n  rownames(mat) = df$learner.id\n  colnames(mat) = task.id.names\n  return(mat)\n}\n\nmatrixRanks = convertModifiedBMRToRankMatrix(res.perfs.df, measure = measure.chosen)\n\n\n\n## General vizualisation -----\nmeasure.chosen = acc\n\n\n\ndf = reshape2::melt(matrixRanks)\ncolnames(df) = c(\"learner.id\", \"task.id\", \"rank\")\n\np = ggplot(df, aes_string(\"rank\", fill = \"learner.id\"))\np = p + geom_bar(position = \"dodge\")\np = p + ylab(NULL)\np = p + ggtitle(paste(\"mesure :\",measure.chosen$id))\nprint(p)\n\n\n# plots for the measures\np <- ggplot(perfsAggr.diff.melted, aes(variable, value))\np + geom_boxplot(aes(colour = variable))\n\np <- ggplot(perfsAggr.diff.melted, aes(variable, value))\np + geom_violin(aes(colour = variable))\n\n\n\n\n## Influence of parameters ----\n\n## Plots\n\n# histogram of features\nhist(df.bmr.diff$logn)\nhist(df.bmr.diff$logp)\nhist(df.bmr.diff$logdimension)\nhist(df.bmr.diff$logpsurn)\nhist(df.bmr.diff$logdimensionsurn)\nhist(df.bmr.diff$lograpportMajorityMinorityClass)\n\n# plot performance vs parameter of the dataset\nplot(df.bmr.diff$logn, df.bmr.diff$acc.test.mean)\nplot(df.bmr.diff$logp, df.bmr.diff$acc.test.mean)\nplot(df.bmr.diff$logdimension, df.bmr.diff$acc.test.mean)\nplot(df.bmr.diff$logpsurn, df.bmr.diff$acc.test.mean)\nplot(df.bmr.diff$logdimensionsurn, df.bmr.diff$acc.test.mean)\nplot(df.bmr.diff$lograpportMajorityMinorityClass, df.bmr.diff$acc.test.mean)\n\n# with the linear models\nplotLinearModelandCor<-function(feature, measure) {\n  plot(df.bmr.diff[[feature]], df.bmr.diff[[measure]], xlab = feature, ylab = measure)\n  fit =lm(df.bmr.diff[[measure]]~df.bmr.diff[[feature]])\n  print(summary(fit))\n  x = seq(-100,100,length.out = 20)\n  lines(x, x*fit$coefficients[2]+fit$coefficients[1], col = \"red\")\n  \n  df.concordance = data.frame(df.bmr.diff[[feature]], df.bmr.diff[[measure]])\n  tau = cor(df.concordance, method=\"kendall\", use=\"pairwise\") # kendall\n  rho = cor(df.concordance, method=\"spearman\", use=\"pairwise\")# spearmann\n  print(paste(\"tau\", tau[1,2]))\n  print(paste(\"rho\", rho[1,2]))\n}\n\n\nplotLinearModelandCor(\"logn\",\"acc.test.mean\")\nplotLinearModelandCor(\"logdimension\",\"acc.test.mean\")\nplotLinearModelandCor(\"logpsurn\",\"acc.test.mean\")\nplotLinearModelandCor(\"logdimensionsurn\",\"acc.test.mean\")\nplotLinearModelandCor(\"lograpportMajorityMinorityClass\",\"acc.test.mean\")\n\n\n\n## Anne Laure visualization\n\n\n# without ggplot\nboxplot.threshold <- function(df, measure, feature, threshold) {\n  \n  names = names(df)\n  \n  if (!(measure %in% names) | !(feature %in% names) ) {\n    print(\"Error, measure or feature was not found\")\n  }\n  \n  df.inferior = subset(df, df[[feature]] < threshold)\n  df.superior = subset(df, df[[feature]] > threshold)\n  \n  boxplot(df.inferior[[measure]])\n  boxplot(df.superior[[measure]])\n}\n\nfeature = \"logp\"\nmeasure = \"acc.test.mean\"\n\n\npar(mfrow=c(3,2))\nboxplot.threshold(df.bmr.diff, \"acc.test.mean\", \"logp\", 1.5)\nboxplot.threshold(df.bmr.diff, \"acc.test.mean\", \"logp\", 2.5)\nboxplot.threshold(df.bmr.diff, \"acc.test.mean\", \"logp\", 3.5)\n\n\n\n\n# with ggplot\nboxplot.threshold.ggplot <- function(df, measure, feature, threshold) {\n  names = names(df)\n  \n  if (!(measure %in% names) | !(feature %in% names) ) {\n    print(\"Error, measure or feature was not found\")\n  }\n  \n  thresh = df[[feature]]>threshold\n  df$thresh = thresh\n  p <- ggplot(df, aes_string(\"thresh\", \"acc.test.mean\"))\n  p = p + geom_boxplot(aes_string(fill = \"thresh\"))\n  return(p)\n}\n\nfeature.boxplot <- function(df, measure, feature, threshold.vect) {\n  n = length(threshold.vect)\n  \n  v = lapply(threshold.vect, function(x) boxplot.threshold.ggplot(df, measure, feature, x))\n}\n\nmeasure.chosen = \"acc.test.mean\"\n\n\n\n# logp\nfeature.chosen = \"logp\"\np1 <- boxplot.threshold.ggplot(df.bmr.diff, measure.chosen, feature.chosen, 1.5)\np2 <- boxplot.threshold.ggplot(df.bmr.diff, measure.chosen, feature.chosen, 2.5)\np3 <- boxplot.threshold.ggplot(df.bmr.diff, measure.chosen, feature.chosen, 3.5)\n\nplot_grid(c(p1, p2, p3),  labels=c(\">5\", \">12\", \">30\"), ncol = 3, nrow = 1)\n\n#logn\nfeature.chosen = \"logn\"\np1 <- boxplot.threshold.ggplot(df.bmr.diff, measure.chosen, feature.chosen, 4.5)\np2 <- boxplot.threshold.ggplot(df.bmr.diff, measure.chosen, feature.chosen, 5.5)\np3 <- boxplot.threshold.ggplot(df.bmr.diff, measure.chosen, feature.chosen, 6.5)\n\nplot_grid(p1, p2, p3,  labels=c(\">4.5\", \">5.5\", \">6.5\"), ncol = 3, nrow = 1)\n\n#logdimension\nfeature.chosen = \"logdimension\"\np1 <- boxplot.threshold.ggplot(df.bmr.diff, measure.chosen, feature.chosen, 1.5)\np2 <- boxplot.threshold.ggplot(df.bmr.diff, measure.chosen, feature.chosen, 2.5)\np3 <- boxplot.threshold.ggplot(df.bmr.diff, measure.chosen, feature.chosen, 3.5)\n\nplot_grid(p1, p2, p3,  labels=c(\">4.5\", \">5.5\", \">6.5\"), ncol = 3, nrow = 1)\n\n\n\n## Partial dependance plots analysis\n",
    "created" : 1471449959997.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2956404378",
    "id" : "1A324463",
    "lastKnownWriteTime" : 1471518594,
    "last_content_update" : 1471518594,
    "path" : "Z:/Raphael/GiHub/IBE_Benchmark-OpenML/benchmark_convertResults.R",
    "project_path" : "benchmark_convertResults.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}