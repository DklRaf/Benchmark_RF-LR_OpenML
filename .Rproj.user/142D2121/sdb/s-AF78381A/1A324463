{
    "collab_server" : "",
    "contents" : "rm(list = ls())\nOS = \"windows\"\nlibrary(mlr)\nlibrary(gridExtra)\nlibrary(ggplot2)\nlibrary(cowplot)\nlibrary(reshape2)\nsetwd(\"Z:/Raphael/GiHub/IBE_Benchmark-OpenML\")\nsource(file = \"benchmark_defs.R\")\n\n## Load and convert the reasults to a data frame ----\nload(file  = \"../Data_BenchmarkOpenMl/Final/Results/Windows/benchmark_results_snow_strat.RData\")\nload(file = \"../Data_BenchmarkOpenMl/Final/DataMining/clas_time.RData\")\n\n# aggregate the results\nres.perfs = lapply(result, function(x) getBMRAggrPerformances(x, as.df=TRUE))\n\n# detect and removes the nas\nres.perfs.nas = which(sapply(res.perfs, function(x) any(is.na(x))))\nres.perfs = res.perfs[-res.perfs.nas]\nclas_used = clas_used[-res.perfs.nas,]\n\n# convert to a data.frame\nres.perfs.df = do.call(\"rbind\", res.perfs) \n\n# get the difference of performances\nperfsAggr.LR = subset(res.perfs.df, learner.id==\"classif.logreg\")\nperfsAggr.RF = subset(res.perfs.df, learner.id==\"classif.randomForest\")\nperfsAggr.diff = perfsAggr.RF[,3:ncol(perfsAggr.RF)]-perfsAggr.LR[,3:ncol(perfsAggr.LR)]\nperfsAggr.diff.melted = melt(perfsAggr.diff)\ndetach(package:reshape2, unload = TRUE)\n\n## Compute the dataset of difference\ndf.bmr.diff = data.frame(perfsAggr.RF[,c(3:ncol(perfsAggr.RF))]-perfsAggr.LR[,c(3:ncol(perfsAggr.LR))],\n                         logp = log(clas_used$NumberOfFeatures), \n                         logn = log(clas_used$NumberOfInstances),\n                         logdimension = log(clas_used$dimension),\n                         logpsurn = log(clas_used$NumberOfFeatures/clas_used$NumberOfInstances),\n                         logdimensionsurn = log(clas_used$dimension/clas_used$NumberOfInstances),\n                         lograpportMajorityMinorityClass = log(clas_used$MajorityClassSize/clas_used$MinorityClassSize))\n\n\npaste(\"Is there any nas ? :\", any(is.na(df.bmr.diff)))\n\n\nmeasures.names = sapply(MEASURES, function(x) paste0(x$id,\".test.mean\"))\nfeatures.names = names(df.bmr.diff)[which(!(names(df.bmr.diff) %in% measures.names))]\n\n## Compute the ranks\nconvertModifiedBMRToRankMatrix <- function(bmr.all, measure = NULL, ties.method = \"average\") {\n  \n  measure.name = paste(measure$id,\".test.mean\", sep = \"\")\n  df = aggregate(bmr.all[[measure.name]], by = list(task.id = bmr.all$task.id,\n                                                    learner.id = bmr.all$learner.id),\n                 FUN = mean)\n  \n  # calculate ranks, rank according to minimize option of the measure\n  if (!measure$minimize)\n    df$x = -df$x\n  df = plyr::ddply(df, \"task.id\", function(d) {\n    d$alg.rank = rank(d$x, ties.method = ties.method)\n    return(d)\n  })\n  \n  # convert into matrix, rows = leaner, cols = tasks\n  df = reshape2::melt(df, c(\"task.id\", \"learner.id\"), \"alg.rank\")\n  df = reshape2::dcast(df, learner.id ~ task.id )\n  task.id.names = setdiff(colnames(df), \"learner.id\")\n  mat = as.matrix(df[, task.id.names])\n  rownames(mat) = df$learner.id\n  colnames(mat) = task.id.names\n  return(mat)\n}\n\n\n\n\n## General vizualisation -----\n\nmeasure.chosen = acc\nmatrixRanks = convertModifiedBMRToRankMatrix(res.perfs.df, measure = measure.chosen)\n\ndf = reshape2::melt(matrixRanks)\ncolnames(df) = c(\"learner.id\", \"task.id\", \"rank\")\n\np = ggplot(df, aes_string(\"rank\", fill = \"learner.id\"))\np = p + geom_bar(position = \"dodge\")\np = p + ylab(NULL)\np = p + ggtitle(paste(\"mesure :\",measure.chosen$id))\nprint(p)\n\n\n# plots for the measures\np <- ggplot(perfsAggr.diff.melted, aes(variable, value))\np + geom_boxplot(aes(colour = variable))\n\np <- ggplot(perfsAggr.diff.melted, aes(variable, value))\np + geom_violin(aes(colour = variable))\n\n\n\n\n## Influence of parameters ----\n\n## Plots\n\n# histogram of features\nhist(df.bmr.diff$logn)\nhist(df.bmr.diff$logp)\nhist(df.bmr.diff$logdimension)\nhist(df.bmr.diff$logpsurn)\nhist(df.bmr.diff$logdimensionsurn)\nhist(df.bmr.diff$lograpportMajorityMinorityClass)\n\n# plot performance vs parameter of the dataset\nplot(df.bmr.diff$logn, df.bmr.diff$acc.test.mean)\nplot(df.bmr.diff$logp, df.bmr.diff$acc.test.mean)\nplot(df.bmr.diff$logdimension, df.bmr.diff$acc.test.mean)\nplot(df.bmr.diff$logpsurn, df.bmr.diff$acc.test.mean)\nplot(df.bmr.diff$logdimensionsurn, df.bmr.diff$acc.test.mean)\nplot(df.bmr.diff$lograpportMajorityMinorityClass, df.bmr.diff$acc.test.mean)\n\n# with the linear models\nplotLinearModelandCor<-function(feature, measure) {\n  plot(df.bmr.diff[[feature]], df.bmr.diff[[measure]], xlab = feature, ylab = measure)\n  fit =lm(df.bmr.diff[[measure]]~df.bmr.diff[[feature]])\n  print(summary(fit))\n  x = seq(-100,100,length.out = 20)\n  lines(x, x*fit$coefficients[2]+fit$coefficients[1], col = \"red\")\n  \n  df.concordance = data.frame(df.bmr.diff[[feature]], df.bmr.diff[[measure]])\n  tau = cor(df.concordance, method=\"kendall\", use=\"pairwise\") # kendall\n  rho = cor(df.concordance, method=\"spearman\", use=\"pairwise\")# spearmann\n  print(paste(\"tau\", tau[1,2]))\n  print(paste(\"rho\", rho[1,2]))\n}\n\n\nplotLinearModelandCor(\"logn\",\"acc.test.mean\")\nplotLinearModelandCor(\"logdimension\",\"acc.test.mean\")\nplotLinearModelandCor(\"logpsurn\",\"acc.test.mean\")\nplotLinearModelandCor(\"logdimensionsurn\",\"acc.test.mean\")\nplotLinearModelandCor(\"lograpportMajorityMinorityClass\",\"acc.test.mean\")\n\n# Importance of the variables\n\n# With linear regression model\nfit.all = lm(df.bmr.diff$acc.test.mean~\n               df.bmr.diff$logp+\n               df.bmr.diff$logn+\n               df.bmr.diff$logdimension+\n               df.bmr.diff$logpsurn+\n               df.bmr.diff$logdimensionsurn+\n               df.bmr.diff$lograpportMajorityMinorityClass)\n\nsummary(fit.all)\n\n# with a random forest\nmeasure.chosen = \"acc.test.mean\"\ndf.regr = data.frame(subset(df.bmr.diff, select = measure.chosen), subset(df.bmr.diff, select = features.names))\ntask.regr = makeRegrTask(data = df.regr, target = measure.chosen)\nfv = generateFilterValuesData(task.regr, method = \"randomForestSRC.rfsrc\")\n\n## Anne Laure visualization\n\n# with ggplot\nboxplot.threshold.ggplot <- function(df, measure, feature, threshold) {\n  names = names(df)\n  \n  if (!(measure %in% names) | !(feature %in% names) ) {\n    print(\"Error, measure or feature was not found\")\n  }\n  \n  thresh = df[[feature]]>threshold\n  df$thresh = thresh\n  p <- ggplot(df, aes_string(\"thresh\", \"acc.test.mean\"))\n  p = p + geom_boxplot(aes_string(fill = \"thresh\"))\n  return(p)\n}\n\nfeature.boxplot <- function(df, measure, feature, threshold.vect) {\n  n = length(threshold.vect)\n  \n  v = lapply(threshold.vect, function(x) boxplot.threshold.ggplot(df, measure, feature, x))\n  labels = sapply(threshold.vect, function(x) return(paste(\">\",x, sep = \"\")))\n  plot_grid(plotlist = v,  labels=labels, ncol = 3, nrow = 1)\n}\n\n\n\nmeasure.chosen = \"acc.test.mean\"\n\n# logp\nfeature.chosen = \"logp\"\nfeature.boxplot(df.bmr.diff, measure.chosen, feature.chosen,c(1.5,2.5,3.5))\n\n# logn\nfeature.chosen = \"logn\"\nfeature.boxplot(df.bmr.diff, measure.chosen, feature.chosen,c(4.5,5.5,6.5))\n\n#logdimension\nfeature.chosen = \"logdimension\"\nfeature.boxplot(df.bmr.diff, measure.chosen, feature.chosen,c(1.5,2.5,3.5))\n\n#logdimension\nfeature.chosen = \"logpsurn\"\nfeature.boxplot(df.bmr.diff, measure.chosen, feature.chosen,c(-4,-3,-2))\n\n#logdimension\nfeature.chosen = \"logdimensionsurn\"\nfeature.boxplot(df.bmr.diff, measure.chosen, feature.chosen,c(-5,-4,-2))\n\n#logdimension\nfeature.chosen = \"lograpportMajorityMinorityClass\"\nfeature.boxplot(df.bmr.diff, measure.chosen, feature.chosen,c(0.2,0.6,1,2))\n\n\n\n\n## Partial dependance plots analysis\n\n## Classification\n\nmeasure.chosen = acc\nmatrixRanks = convertModifiedBMRToRankMatrix(res.perfs.df, measure = measure.chosen)\n\nlrn.classif.rf = makeLearner(\"classif.randomForest\", predict.type = \"prob\")\n\n\ndf.classif = data.frame(rankrf = matrixRanks[2,], subset(df.bmr.diff, select = features.names))\nindex.egalite = which(df.classif$rankrf==1.5)\ndf.classif = df.classif[-index.egalite,]\ndf.classif$rankrf = as.factor(df.classif$rankrf)\n\ntask.classif = makeClassifTask(data = df.classif, target = \"rankrf\")\ntask.classif$env$data$logn = as.numeric(task.classif$env$data$logn)\n\nfit.classif.rf = train(lrn.classif.rf, task.classif)\n\n# 1D partial dependance plots\npd.classif = generatePartialDependenceData(fit.classif.rf, task.classif, \"logn\")\nplotPartialDependence(pd.classif)\n\npd.classif = generatePartialDependenceData(fit.classif.rf, task.classif, \"logp\")\nplotPartialDependence(pd.classif)\n\npd.classif = generatePartialDependenceData(fit.classif.rf, task.classif, \"logdimension\")\nplotPartialDependence(pd.classif)\n\npd.classif = generatePartialDependenceData(fit.classif.rf, task.classif, \"logpsurn\")\nplotPartialDependence(pd.classif)\n\npd.classif = generatePartialDependenceData(fit.classif.rf, task.classif, \"logdimensionsurn\")\nplotPartialDependence(pd.classif)\n\npd.classif = generatePartialDependenceData(fit.classif.rf, task.classif, \"lograpportMajorityMinorityClass\")\nplotPartialDependence(pd.classif)\n\n\n# 2D Partial dependance plots\npd.classif = generatePartialDependenceData(fit.classif.rf, task.classif, c(\"logn\", \"logp\"), interaction = TRUE)\nplotPartialDependence(pd.classif, geom = \"tile\")\n\n\n\n## regression\nmeasure.chosen = \"acc.test.mean\"\ntask.regr = makeRegrTask(data = df.regr, target = measure.chosen)\nlrn.regr = makeLearner(\"regr.randomForest\")\ntask.regr$env$data$logn=as.numeric(task.regr$env$data$logn)\nfit.regr.rf = train(lrn.regr, task.regr)\n\n# 1D partial dependance plots\npd.regr.rf = generatePartialDependenceData(fit.regr.rf, task.regr,features = c(\"logn\"), fun = function(x) quantile(x, c(.25, .5, .75)))\nplotPartialDependence(pd.regr.rf)\n\npd.regr.rf = generatePartialDependenceData(fit.regr.rf, task.regr,features = c(\"logp\"),fun = function(x) quantile(x, c(.25, .5, .75)))\nplotPartialDependence(pd.regr.rf)\n\npd.regr.rf = generatePartialDependenceData(fit.regr.rf, task.regr,features = c(\"logdimension\"), fun = function(x) quantile(x, c(.25, .5, .75)))\nplotPartialDependence(pd.regr.rf)\n\npd.regr.rf = generatePartialDependenceData(fit.regr.rf, task.regr,features = c(\"logpsurn\"),fun = function(x) quantile(x, c(.25, .5, .75)))\nplotPartialDependence(pd.regr.rf)\n\npd.regr.rf = generatePartialDependenceData(fit.regr.rf, task.regr,features = c(\"logdimensionsurn\"),fun = function(x) quantile(x, c(.25, .5, .75)))\nplotPartialDependence(pd.regr.rf)\n\npd.regr.rf = generatePartialDependenceData(fit.regr.rf, task.regr,features = c(\"lograpportMajorityMinorityClass\"),fun = function(x) quantile(x, c(.25, .5, .75)))\nplotPartialDependence(pd.regr.rf)\n\n\n\n# 2D Partial dependance plots\npd.regr.rf = generatePartialDependenceData(fit.regr.rf, task.regr,features = c(\"logdimensionsurn\", \"lograpportMajorityMinorityClass\"), interaction = TRUE)\nplotPartialDependence(pd.regr.rf, geom = \"tile\")\n",
    "created" : 1471449959997.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "429520708",
    "id" : "1A324463",
    "lastKnownWriteTime" : 1471597520,
    "last_content_update" : 1471597520,
    "path" : "Z:/Raphael/GiHub/IBE_Benchmark-OpenML/benchmark_convertResults.R",
    "project_path" : "benchmark_convertResults.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}